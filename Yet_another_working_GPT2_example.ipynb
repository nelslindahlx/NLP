{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yet another working GPT2 example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3sMTD2rp0FP",
        "colab_type": "text"
      },
      "source": [
        "This was working code on 6/6/2020."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53rjf4T1CHsR",
        "colab_type": "text"
      },
      "source": [
        "# Working example of GPT-2 using gpt-2-simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWxTLEm3COGd",
        "colab_type": "text"
      },
      "source": [
        "The best method to use the OpenAI GPT-2 model is via gpt-2-simple. It works well enough. Some methods that I tried and that failed are commented out before it. The only method that seems to work is the gpt-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4caFK3Zd_O7V",
        "colab_type": "code",
        "outputId": "a9947c66-3f57-4cae-f594-ac6775655b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# !pip uninstall tensorflow -y \n",
        "# !pip uninstall tensorflow-gpu -y\n",
        "# !pip install tensorflow==1.14\n",
        "# !pip install tensorflow-gpu==1.4.1\n",
        "# !pip3 install tensorflow==1.12.0\n",
        "!pip install gpt-2-simple"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.18.4)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=b2c8d8fded02f81a850a8ef6c98acb28f341ba7aec1093f2f7d5ab79814f99c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkoGbGniCdrV",
        "colab_type": "text"
      },
      "source": [
        "You can now use the 1x TensorFlow selection and check what GPU you have. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymSkRj-g-6Om",
        "colab_type": "code",
        "outputId": "dbab9d19-ec6b-4f4a-c954-da330926551a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Sat Jun  6 17:46:12 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vGu6fSdDSVR",
        "colab_type": "text"
      },
      "source": [
        "This is our import of the GPT-2 we installed above. You get the warning that is the root of the GPT-2 problem noting that \"The TensorFlow contrib module will not be included in TensorFlow 2.0.'\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC3ohher-i-U",
        "colab_type": "code",
        "outputId": "9dd1d022-2fae-4fa8-d637-bc0704a8ea23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crNiRrIeDv5z",
        "colab_type": "text"
      },
      "source": [
        "This snippet is using the 355M model. The other model numbers are commented out above for later adventure "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CJwM6gA-rx5",
        "colab_type": "code",
        "outputId": "9ac50927-dec2-4802-d5af-15ca91eeb8b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# !python3 download_model.py 124M\n",
        "# !python3 download_model.py 355M\n",
        "# !python3 download_model.py 774M\n",
        "# !python3 download_model.py 1558M\n",
        "model_name = \"355M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "\tprint(f\"Downloading {model_name} model...\")\n",
        "\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /content/models\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 637Mit/s]                                                      "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading 355M model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fetching encoder.json: 1.05Mit [00:00, 140Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 1.15Git/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:13, 107Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 609Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 105Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 241Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IguZVojTE3g_",
        "colab_type": "text"
      },
      "source": [
        "This will take a couple minutes to run... it has a \"ZeroDivisionError\" but still works in the next step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ616xHk-uut",
        "colab_type": "code",
        "outputId": "aaede94f-f7eb-4108-e8fa-9fde4559c83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "file_name = \"maps.txt\"\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              file_name,\n",
        "              model_name=model_name,\n",
        "              steps=300)  # This is reduced to 300. It could be a larger value\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 0 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1f7f488b5cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m               steps=300)  \n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 (_, v_loss, v_summary) = sess.run(\n\u001b[1;32m    341\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mopt_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                     feed_dict={context: sample_batch()})\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0msummary_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36msample_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_from\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'latest'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_from\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'latest'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/load_dataset.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         assert length < self.total_size // len(\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset files are too small to sample {} tokens at a time\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             length)\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPYTWFKXEsh_",
        "colab_type": "text"
      },
      "source": [
        "This makes text using the model from above..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcPgaPmDjWxe",
        "colab_type": "text"
      },
      "source": [
        "# Let's make some outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le6wo9vY-xuO",
        "colab_type": "code",
        "outputId": "31383c8f-e81b-446f-baa1-785411cb5457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "single_text = gpt2.generate(sess, prefix=\"What makes Phil happy\")\n",
        "print(single_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What makes Phil happy?\n",
            "\n",
            "\"I'm just a guy who has been fortunate enough to get to play some great teams, and I think that's the biggest thing. I think we're all having fun, and it's really fun to go out there and play great basketball.\n",
            "\n",
            "\"I think everyone enjoys being able to go out there and play some great basketball, and hopefully it helps us win a championship.\"<|endoftext|>Have you ever heard of the \"Tanglewood\" sound they have made with their new album? It is a titanic, bass heavy music that you can feel your feet dragging on the concrete. It is as if a pair of giant, metal and heavy flowing boots have been made of wood instead of steel. And it is the perfect blend of funk and rock.\n",
            "\n",
            "They have earned their fame through their \"otherworldly\" live performances, or the \"Tanglewood\" thing, which is what they have come to be known for. The band plays at countless music festivals in the country, but the Tanglewood is different. It is an American pop group that speaks to and connects with an American audience. The Rock and Roll Hall of Fame induction, which they earned in December, has been nothing short of incredible.\n",
            "\n",
            "I have been lucky enough to see them perform on numerous occasions. The most recent was the evening of their new album release in late November. It was a surreal experience in a field full of fans, local and foreign, that were filled with love. They seemed to be shining a light on the American music scene. They gave a great, honest performance, but they still gave a great show.\n",
            "\n",
            "I had a chance to speak with Kristian, co-founder of Tanglewood, to learn more about the band and what it means to him. He is not just an influential artist in the music scene, but a person that is instrumental in the life of many musicians, as well. He is an illustrator, a photographer, a writer and a composer of pop songs for music videos and the like. He is also a musician, and has been a touring musician for the last few years. He said he has been inspired by many of the artists who have come before him.\n",
            "\n",
            "But he is not just a \"rock and roll\" artist, as he has also created and performed and written acclaimed music that has helped shape and informed the music industry. For example, his theme song \"One Hundred Years of Love\" was recorded by Madonna when she was only 14 years old, and has been used in countless movies, commercials and live music videos.\n",
            "\n",
            "He wrote and recorded a song called \"Coup du Diable\", which means \"We Are the Cutest Dream That Ever Lived\", a song called \"Trapez\", which means \"Long Live the Mob\", and \"Even Down To Earth\" which describes the story of the discovery of the first American gold in the late 1700's.\n",
            "\n",
            "I found Kristian's story to be very fascinating. He is a story teller, and is constantly telling stories which inspire others. He has the ability to terrify and inspire others. It feels as if the Tanglewood is living the life of its artists, as they are creating and performing music on a daily basis.\n",
            "\n",
            "Kristian spoke about the importance of fans and their feelings in a recent interview.\n",
            "\n",
            "\"I think it's important to have people that are still interested in you and have a desire to listen to your music. It's a lot more honest to them that way. . They were people that were in the mood to listen to a song and are not interested in the rest of it, so we wanted to be able to drop them a note, or at least to hear them sing the song, and that was an important part of the whole thing.\"\n",
            "\n",
            "They also play in several other bands and clubs around the city, and have become a community. The bill at the Rock and Roll Hall of Fame, (which they received in December) is a testament to their sheer variety. They play great music, but they also had a band named the \"Gettin' Tree\" that came out of both the Tanglewood and the One Hundred Years of Love.\n",
            "\n",
            "I would say, audiences are definitely drawn to them, and they are truly a unique and exciting band.\n",
            "\n",
            "Thank you Kristian for taking the time to speak with me. Keep up the amazing work, and keep up the amazing fans!\n",
            "\n",
            "Artwork by Freckles\n",
            "\n",
            "See more Tanglewood photos by the author here.<|endoftext|>Halliburton's \"sophisticated\" internal auditing system won't cure the company's longstanding problems with its management and accounting practices, a top internal watchdog said Monday.\n",
            "\n",
            "The two-year, $20 million audit, which examined the company's internal accounting and other processes, added to the scrutiny of the company's management and accounting practices as the Department of Justice seeks to bring criminal charges against top executives.\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W_9WloJNEgOD",
        "outputId": "16f144dc-e80c-4129-9dad-c6c09e9a1146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "single_text = gpt2.generate(sess, prefix=\"Why does Phil love snacks\")\n",
        "print(single_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why does Phil love snacks, of course?\n",
            "\n",
            "\"My favorite part of it is the walk — walking into the room and meeting every single person in the room and knowing that everybody's a friend,\" he says. \"That's what I love about the show. It's like you're surrounded by people. It's like you're right in the middle of families, so it's a great feeling. It's not necessarily something that you do in the real world.\"\n",
            "\n",
            "The Simpsons is one of the world's most enduring shows, and it has helped leave a lasting mark on the minds of millions of people around the world. But the show's popularity wasn't always smooth. The show first debuted on April 19, 1964, on the ABC network. It aired for the first time on July 8, 1966, on NBC.\n",
            "\n",
            "More than 15 years after its debut, the show is still on the air. It's been on the air for nearly 85 years. But it's been almost as long since The Simpsons has been on the air — a fact that makes the show's popularity all the more remarkable. To celebrate the show's 90th anniversary, we spoke to the show's creator, Matt Groening, about what it's been like to write the show, and what it feels like to be the creator of a show that's been on the air for nearly 85 years.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "What inspired you to write The Simpsons?\n",
            "\n",
            "Matt Groening: I grew up in Portland, Oregon, and it was in the '50s, and I would read all the books on the city and I would read every book on the train by the time I got back to my hotel. And I would try to get as many of them as I could. My whole family was on the train, and I was lucky enough to talk to all the people on the train. I got to meet all the characters and interact with those people, and it made me really think about how there are so many different ways to live. And when I came up with the idea for The Simpsons, I didn't know what it would be like, and I didn't want to just blow it, I wanted to make it, and I could have written it any way that I wanted.\n",
            "\n",
            "I had tons of ideas about this show, but I didn't know where it would take me. And so I wrote it, and I thought, \"Well, I'm going to do it my way, and I'm going to do it in a way that is kind of comedic, because that's what I'm good at.\" So I got to work on the writing, and I got to work on the story, and then I got to work on the character writing. And then I spent about two weeks in the writers' room and I wrote the character. And then I did the story, and then I got the script, and now it's on the air. I hope that's a good place to start.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "What was it like making the show without any experience writing for the show?\n",
            "\n",
            "Matt Groening: I've written stuff, and I've written commercials, and I've been on TV, and I've written shows for both shows. I knew that what I wrote was going to be funny. But I knew that the writing and the acting were going to be different, so I made the transition better. We talked about what we wanted it to look like and how we wanted it to sound like, and we tried to formulate the tone and the story, and then got to work on the characters and the characters wrote the story.\n",
            "\n",
            "It's remarkable how much time everyone involved spent on the show. It was a lot of work.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "MATT GROENING: It was a lot of work, and I think that that's something that I wish I had done as part of the job. I think that was one of the craziest things that I've ever done.\n",
            "\n",
            "Did you make a conscious decision to write the story and the characters in a different way?\n",
            "\n",
            "MATT GROENING: No, we really didn't. I don't think our creative team knew what we wanted it to be. I don't think they knew what our audience wanted. I don't think we had a message for it. We just wrote it, and we tried to make it fun and interesting, and we tried to write a story that would have any possibility of working for television. And I think we succeeded.\n",
            "\n",
            "Do you know how many people watched The Simpsons?\n",
            "\n",
            "MATT GROENING: I don't think we knew how many people watched the show. I think it was probably more than a million people. That's a lot of people watching it. I know some people watched it for the first time when I came on. I know some people watched it because it was the first time that they'd ever seen it. And then I think it\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
